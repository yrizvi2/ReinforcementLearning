{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "06903bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "from hiive.mdptoolbox.mdp import ValueIteration, PolicyIteration, QLearning\n",
    "def random_restart_environment(env):\n",
    "    random_state = np.random.choice(range(env.observation_space.n))\n",
    "    env.env.s = random_state\n",
    "    return random_state\n",
    "\n",
    "# suppress pandas warning\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "# set seed\n",
    "np.random.seed(42)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9551fbde",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = {\n",
    "    b'S': 'b',\n",
    "    b'F': 'w',\n",
    "    b'H': 'k',\n",
    "    b'G': 'g'\n",
    "}\n",
    "\n",
    "directions = {\n",
    "            0: '←',\n",
    "            1: '↓',\n",
    "            2: '→',\n",
    "            3: '↑'\n",
    "}\n",
    "\n",
    "def plot_lake(env, policy=None, title='Frozen Lake'):\n",
    "    squares = env.nrow\n",
    "    fig = plt.figure(figsize=(6, 6))\n",
    "    ax = fig.add_subplot(111, xlim=(-.01, squares+0.01), ylim=(-.01, squares+0.01))\n",
    "    plt.title(title, fontsize=16, weight='bold', y=1.01)\n",
    "    for i in range(squares):\n",
    "        for j in range(squares):\n",
    "            y = squares - i - 1\n",
    "            x = j\n",
    "            p = plt.Rectangle([x, y], 1, 1, linewidth=1, edgecolor='k')\n",
    "            p.set_facecolor(colors[env.desc[i,j]])\n",
    "            ax.add_patch(p)\n",
    "            \n",
    "            if policy is not None:\n",
    "                text = ax.text(x+0.5, y+0.5, directions[policy[i, j]],\n",
    "                               horizontalalignment='center', size=25, verticalalignment='center',\n",
    "                               color='k')\n",
    "            \n",
    "    plt.axis('off')\n",
    "    \n",
    "#plot_lake(env, policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e8276e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score(env, policy, episodes=1000):\n",
    "    misses = 0\n",
    "    steps_list = []\n",
    "    successes = 0  # Track the number of successful episodes\n",
    "    for episode in range(episodes):\n",
    "        observation = env.reset()\n",
    "        steps = 0\n",
    "        while True:\n",
    "            action = policy[observation]\n",
    "            observation, reward, done, _ = env.step(action)\n",
    "            steps += 1\n",
    "            if done and reward == 1:\n",
    "                steps_list.append(steps)\n",
    "                successes += 1  # Increment successful episodes count\n",
    "                break\n",
    "            elif done and reward == 0:\n",
    "                misses += 1\n",
    "                break\n",
    "    \n",
    "    if successes == 0:\n",
    "        pct_fail = 100.0  # All episodes failed\n",
    "        ave_steps = np.nan  # No successful episodes, set average steps to NaN\n",
    "        std_steps = np.nan  # No successful episodes, set standard deviation to NaN\n",
    "    else:\n",
    "        pct_fail = (misses / successes) * 100\n",
    "        ave_steps = np.mean(steps_list)\n",
    "        std_steps = np.std(steps_list)\n",
    "    \n",
    "    print('----------------------------------------------')\n",
    "    print('You took an average of {:.0f} steps to get the frisbee'.format(ave_steps))\n",
    "    print('And you fell in the hole {:.2f} % of the times'.format(pct_fail))\n",
    "    print('----------------------------------------------')\n",
    "    \n",
    "    return ave_steps, std_steps, pct_fail\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d4548051",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code based on:\n",
    "# https://medium.com/analytics-vidhya/solving-the-frozenlake-environment-from-openai-gym-using-value-iteration-5a078dffe438\n",
    "def get_policy(env,stateValue, lmbda=0.9):\n",
    "    policy = [0 for i in range(env.nS)]\n",
    "    for state in range(env.nS):\n",
    "        action_values = []\n",
    "        for action in range(env.nA):\n",
    "            action_value = 0\n",
    "            for i in range(len(env.P[state][action])):\n",
    "                prob, next_state, r, _ = env.P[state][action][i]\n",
    "                action_value += prob * (r + lmbda * stateValue[next_state])\n",
    "            action_values.append(action_value)\n",
    "        best_action = np.argmax(np.asarray(action_values))\n",
    "        policy[state] = best_action\n",
    "    return policy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d792235a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Setup 4x4\n",
    "env = gym.make('FrozenLake-v1').unwrapped\n",
    "\n",
    "env.max_episode_steps=250\n",
    "rows = env.nrow\n",
    "cols = env.ncol\n",
    "T = np.zeros((4, rows*cols, rows*cols))\n",
    "R = np.zeros((4, rows*cols, rows*cols))\n",
    "\n",
    "old_state = np.inf\n",
    "\n",
    "for square in env.P:\n",
    "    for action in env.P[square]:\n",
    "        for i in range(len(env.P[square][action])):\n",
    "            new_state = env.P[square][action][i][1]\n",
    "            if new_state == old_state:\n",
    "                T[action][square][env.P[square][action][i][1]] = T[action][square][old_state] + env.P[square][action][i][0]\n",
    "                R[action][square][env.P[square][action][i][1]] = R[action][square][old_state] + env.P[square][action][i][2]\n",
    "            else:\n",
    "                T[action][square][env.P[square][action][i][1]] = env.P[square][action][i][0]\n",
    "                R[action][square][env.P[square][action][i][1]] = env.P[square][action][i][2]\n",
    "            old_state = env.P[square][action][i][1]\n",
    "            \n",
    "#print(T)\n",
    "#print(R)\n",
    "plot_lake(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a1328924",
   "metadata": {},
   "outputs": [],
   "source": [
    "def valueIteration(t, r, gammas, epsilons, showResults=False, max_iterations=100000):\n",
    "    t0 = time.time()\n",
    "    # create data structure to save off\n",
    "    columns = ['gamma', 'epsilon', 'time', 'iterations', 'reward', 'average_steps', 'steps_stddev', 'success_pct', 'policy', 'mean_rewards', 'max_rewards', 'error']\n",
    "    data = pd.DataFrame(0.0, index=np.arange(len(gammas)*len(epsilons)), columns=columns)\n",
    "    \n",
    "    print('Gamma,\\tEps,\\tTime,\\tIter,\\tReward')\n",
    "    print(80*'_')\n",
    "    \n",
    "    testNum = 0\n",
    "    for g in gammas:\n",
    "        for e in epsilons:\n",
    "            test = ValueIteration(t, r, gamma=g, epsilon=e, max_iter=max_iterations)\n",
    "            \n",
    "            runs  = test.run()\n",
    "            Time  = runs[-1]['Time']\n",
    "            iters = runs[-1]['Iteration']\n",
    "            maxR  = runs[-1]['Max V']\n",
    "            \n",
    "            max_rewards, mean_rewards, errors = [], [], []\n",
    "            for run in runs:\n",
    "                max_rewards.append(run['Max V'])\n",
    "                mean_rewards.append(run['Mean V'])\n",
    "                errors.append(run['Error'])\n",
    "            \n",
    "            policy = np.array(test.policy)\n",
    "            policy = policy.reshape(4,4)\n",
    "            \n",
    "            data['gamma'][testNum]        = g\n",
    "            data['epsilon'][testNum]      = e\n",
    "            data['time'][testNum]         = Time\n",
    "            data['iterations'][testNum]   = iters\n",
    "            data['reward'][testNum]       = maxR\n",
    "            data['mean_rewards'][testNum] = np.mean(mean_rewards) if mean_rewards else 0\n",
    "            data['max_rewards'][testNum] = max(max_rewards) if max_rewards else 0\n",
    "            data['error'][testNum] = max(errors) if errors else 0\n",
    "            data['policy'][testNum] = ','.join(map(str, list(test.policy)))\n",
    "            \n",
    "            print('%.2f,\\t%.0E,\\t%.2f,\\t%d,\\t%f' % (g, e, Time, iters, maxR))\n",
    "            \n",
    "            if showResults:\n",
    "                title = 'FrozenLake_VI_' + str(rows) + 'x' + str(cols) + '_g' + str(g) + '_e' + str(e)\n",
    "                plot_lake(env, policy, title)\n",
    "            \n",
    "            testNum = testNum + 1\n",
    "                \n",
    "    endTime = time.time() - t0\n",
    "    print(\"Time taken: %.2f\" %endTime)\n",
    "    \n",
    "    # See differences in policy\n",
    "    policies = data['policy']\n",
    "    \n",
    "    for i,p in enumerate(policies):\n",
    "        pol = list(p)[0]\n",
    "        steps, steps_stddev, failures = get_score(env, pol, showResults)\n",
    "        data['average_steps'][i] = steps\n",
    "        data['steps_stddev'][i]  = steps_stddev\n",
    "        data['success_pct'][i]   = 100-failures      \n",
    "        \n",
    "    # replace all NaN's\n",
    "    data.fillna(0, inplace=True)\n",
    "    data.head()\n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "767c528a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gamma,\tEps,\tTime,\tIter,\tReward\n",
      "________________________________________________________________________________\n",
      "0.10,\t1E-02,\t0.00,\t1,\t0.333333\n",
      "0.10,\t1E-05,\t0.00,\t4,\t0.345235\n",
      "0.10,\t1E-08,\t0.00,\t7,\t0.345239\n",
      "0.10,\t1E-12,\t0.00,\t11,\t0.345239\n",
      "0.30,\t1E-02,\t0.00,\t3,\t0.373333\n",
      "0.30,\t1E-05,\t0.00,\t8,\t0.375101\n",
      "0.30,\t1E-08,\t0.00,\t13,\t0.375103\n",
      "0.30,\t1E-12,\t0.00,\t20,\t0.375103\n",
      "0.60,\t1E-02,\t0.00,\t6,\t0.445120\n",
      "0.60,\t1E-05,\t0.00,\t17,\t0.447647\n",
      "0.60,\t1E-08,\t0.00,\t29,\t0.447649\n",
      "0.60,\t1E-12,\t0.00,\t46,\t0.447649\n",
      "0.90,\t1E-02,\t0.00,\t26,\t0.637540\n",
      "0.90,\t1E-05,\t0.00,\t77,\t0.639019\n",
      "0.90,\t1E-08,\t0.00,\t128,\t0.639020\n",
      "0.90,\t1E-12,\t0.01,\t195,\t0.639020\n",
      "Time taken: 0.06\n",
      "----------------------------------------------\n",
      "You took an average of nan steps to get the frisbee\n",
      "And you fell in the hole 100.00 % of the times\n",
      "----------------------------------------------\n",
      "----------------------------------------------\n",
      "You took an average of nan steps to get the frisbee\n",
      "And you fell in the hole 100.00 % of the times\n",
      "----------------------------------------------\n",
      "----------------------------------------------\n",
      "You took an average of nan steps to get the frisbee\n",
      "And you fell in the hole 100.00 % of the times\n",
      "----------------------------------------------\n",
      "----------------------------------------------\n",
      "You took an average of nan steps to get the frisbee\n",
      "And you fell in the hole 100.00 % of the times\n",
      "----------------------------------------------\n",
      "----------------------------------------------\n",
      "You took an average of nan steps to get the frisbee\n",
      "And you fell in the hole 100.00 % of the times\n",
      "----------------------------------------------\n",
      "----------------------------------------------\n",
      "You took an average of nan steps to get the frisbee\n",
      "And you fell in the hole 100.00 % of the times\n",
      "----------------------------------------------\n",
      "----------------------------------------------\n",
      "You took an average of nan steps to get the frisbee\n",
      "And you fell in the hole 100.00 % of the times\n",
      "----------------------------------------------\n",
      "----------------------------------------------\n",
      "You took an average of nan steps to get the frisbee\n",
      "And you fell in the hole 100.00 % of the times\n",
      "----------------------------------------------\n",
      "----------------------------------------------\n",
      "You took an average of nan steps to get the frisbee\n",
      "And you fell in the hole 100.00 % of the times\n",
      "----------------------------------------------\n",
      "----------------------------------------------\n",
      "You took an average of nan steps to get the frisbee\n",
      "And you fell in the hole 100.00 % of the times\n",
      "----------------------------------------------\n",
      "----------------------------------------------\n",
      "You took an average of nan steps to get the frisbee\n",
      "And you fell in the hole 100.00 % of the times\n",
      "----------------------------------------------\n",
      "----------------------------------------------\n",
      "You took an average of nan steps to get the frisbee\n",
      "And you fell in the hole 100.00 % of the times\n",
      "----------------------------------------------\n",
      "----------------------------------------------\n",
      "You took an average of nan steps to get the frisbee\n",
      "And you fell in the hole 100.00 % of the times\n",
      "----------------------------------------------\n",
      "----------------------------------------------\n",
      "You took an average of nan steps to get the frisbee\n",
      "And you fell in the hole 100.00 % of the times\n",
      "----------------------------------------------\n",
      "----------------------------------------------\n",
      "You took an average of nan steps to get the frisbee\n",
      "And you fell in the hole 100.00 % of the times\n",
      "----------------------------------------------\n",
      "----------------------------------------------\n",
      "You took an average of nan steps to get the frisbee\n",
      "And you fell in the hole 100.00 % of the times\n",
      "----------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/jt/7yzgm5mx5pvbbndt900r1s0m0000gn/T/ipykernel_25377/583246607.py:37: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  data['policy'][testNum] = ','.join(map(str, list(test.policy)))\n"
     ]
    }
   ],
   "source": [
    "gammas   = [0.1, 0.3, 0.6, 0.9]\n",
    "epsilons = [1e-2, 1e-5, 1e-8, 1e-12]\n",
    "vi_data  = valueIteration(T, R, gammas, epsilons, showResults=False)\n",
    "\n",
    "interest = ['gamma', 'epsilon', 'time', 'iterations', 'reward']\n",
    "df = vi_data[interest]\n",
    "#vi_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f88dc1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file_path = \"results-frozenlake.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "03b330c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(csv_file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd82e9db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
